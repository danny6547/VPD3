insertDNVGLIntoRaw: test          
# sortOnDateTime: test              
# updateAirDensity: test            
# updateBrakePower: test            
# updateDisplacement: test          
# updateExpectedSpeed: test         
# updateMassFuelOilConsumed: test   
# updateShaftPower: test            
# updateSpeedLoss: test             
# updateWindResistanceCorrection: test     
# updateWindResistanceRelative: test     
# updateAirResistance: test     
# updateTransProjAreaCurrent: test
# updateCorrectPower: test     
# updateWindResistanceCorrection: write   
# updateAirResistance: write     
# updateCorrectPower: write       
# updateAirDensity: write            
# updateBrakePower: write            
# updateDisplacement: write          
# updateExpectedSpeed: write         
# updateMassFuelOilConsumed: write   
# updateShaftPower: write            
# updateSpeedLoss: write        
ISO19030: test
ISO19030: write
# updateDeliveredPower: test
# updateDeliveredPower: write
# isShaftPowerAvailable: test
# isShaftPowerAvailable: write
# isBrakePowerAvailable: test
# isBrakePowerAvailable: write
# convertDNVGLRawToRawData: write
insertDNVGLIntoPerformance: test
insertDNVGLIntoPerformance: write
# updateExpectedSpeed: include conditions for admiralty formula
# updateExpectedSpeed: include conditions for admiralty formula, test
# updateExpectedSpeed: include conditions for admiralty formula, write
insertIntoSpeedPowerCoefficients: calculate R2 value and validate against ISO standard (0.8)
# updateAirResistanceNoWind: find coefficient in bin containing direction zero (create BinCentres Column in WindCoefficientDirection?)
createRawData: modify double precision to reflect real-world values
updateBrakePower: allow for multiple engines per IMO
bunkerDeliveryNote: make BDN_number unique. This will both ensure that no duplicates rows are added when adding notes from different ships, and that only one value can be indexed for raw data.
# updateLCVFuelOil: test
# updateLCVFuelOil: write
insertWithoutDuplicates: test
# insertWithoutDuplicates: write
# updateLCVFuelOil: rename to updateFromBunkerNote, include update of density value
# removeInvalidRecords: test for remove rows where: mfoc is zero,
# removeInvalidRecords: write
updateBrakePower: make compatible with arbitrary-frequency data
# removeFOCBelowMinimum: remove values of Mfoc below the minimum FOC of the SFOC reference curve.
# deleteWithReferenceConditions: test remove values corresponding to those failing the reference conditions in the standard.
# deleteWithReferenceConditions: write
# insertBunkerDeliveryNoteDNVGL: write
insertBunkerDeliveryNoteDNVGL: test

# filterSpeedPowerLookup: update displacement and trim filters for speed-power values
# filterSpeedPowerLookup: test
# filterSpeedPowerLookup: write
# vessels: column "Speed Power Source", where data was sourced from.
# updateExpectedSpeed: test for multiple-displacement power curves
# updateExpectedSpeed: write for multiple-displacement power curves
Vessels.Speed_Power_Source: what if file is moved? Generate ordered, protected, easily expandable dir structure.
# sensorRecalibration: create table for dates and nature of sensor recalibration (imo, sensor, description)
# filterPowerBelowMinimum: filter values of Delivered Power below the minimum power of the speed-power curve.
# filterPowerBelowMinimum: test
# filterPowerBelowMinimum: write
# normaliseFrequencies: update all columns by normalising frequencies based on formula 2.
# normaliseHigherFreq: average higher-freq data to a lower frequency
# normaliseHigherFreq: write
# normaliseHigherFreq: test
# normaliseLowerFreq: duplicate lower-freq data to a higher frequency
# normaliseLowerFreq: write
# normaliseLowerFreq: test
# updateChauvenetsCriteria: mark rows for filtering for non-angle variables.
# updateChauvenetCriteria: calculate mean and error of angles from formula I2.
# validteData: applies formulae in annex J
# validteData: test
# validteData: write
# validteData: update for standard error of angles calculations

# Sensors: create table to store sensors and their accuracies
# ISO19030Compliant: create table to store boolean indicating whether analysis was compliant with standard
# checkSensorRequirements: (validateFrequencies) insert value for column "Compliant" into table ISO19030Compliant based on comparison of values in Sensors and the requirements in the standard

# PerformanceData: rename to PerformanceDataDNVGL
? PerformanceDataISO19030: create table for data processed from ISO19030
# insertPerformanceDataISO19030: insert performance data derived from RawData into PerformanceDataISO19030 (insertIntoPerformanceData)

propulsiveEfficiency: figure out how to calculate EtaD for "calm" and "actual voyage" conditions

? staticShip: insert static ship data ie speed-power, LBP, (table vessels works for now)
updateKPI: calculate dd performance, in-service performance (out of scope of this project?)

# Find script behind procedure addTimeDNVGLRaw;
? Delete table DNVGLRaw, rewrite loadInfileDNVGLRaw to load data into tempRaw, make ready for RawData, insert without duplicates to RawData;
# updateWindResistanceCorrection: make select from speedPower table based on IMO (EtaD, TA, Crw, C0w)
# call filtering and outlier finding procedures from ISO19030 procedure.

# FiltSPDispTrim: should be true if either Disp or Trim is true?
# FiltSPBelow: currently all NULL
# CauvenetFilt: all NULL
# Validated: all NULL
# AllFilt: all NULL
# Check all tested procedures are called from ISO19030.
	# call updateAirDensity before updateAirResistanceNoWind and updateWindResistanceRelative
	# call updateTransProjArea before updateWindResistanceRelative and updateAirResistanceNoWind
	# call updateFromBunkerNote before updateMassFuelOilConsumed
	# call deleteWithReferenceConditions
	# call deleteWithReferenceConditions
	# call normaliseHigherFreq
	# call normaliseLowerFreq
	# call updateChauvenetCriteria
	# call updateValidated
# Create naming convention for filter columns. (all start with Filter_)
Create matrix of vessels, filter columns.
# updateFromBunkerNote: if no data found, assign defaults
removeInvalidRecords: check for entirely NULL rows ?
# removeFOCBelowMinimum, filterSFOCOutOfRange: change from DELETE to new filter column
# deleteWithReferenceConditions: change from DELETE to new filter column
# insertFromDNVGLRawIntoRaw: reduce run time to less than 1s. (1.4s, close enough)
# ChauvenetFilt: verify no change after data with too-high frequency input, standard compliance updated
# Validated: verify no change after data with too-high frequency input, standard compliance updated


# Pull "Vessel Performance" into Database repo, copy methods into cV (history
# of cVA will exist in repo along with others, but won't "follow" the 
# methods from one file to the other. Commit message stating that methods 
# are being moved will have to do).
# Copy methods from cVA to cV
# Copy methods from cHPDB to cV
	Both methods return cV array, either row vect if no DD data in DB or 
	matrix otherwise
# Create property DryDockInterval for cV
# Write iteration methods for cV
# Replace existing iteration calls with new ones
# Write constructor sub call to detect file inputs or IMO inputs
Write cV.loadFilePerformance

updateFromBunkerNote: Include warnings if some BDN numbers not found in BunkerDeliveryNote table?
Extract "timestep" into high-level metadata table

# Organise repository:
	# Tidy up folders
	# Remove redundant files
	# Remove redundant procedures
	# Remove redundant tables
	# Rename database
# Investigate withoutDuplicates performance issues (replace with unique constraints)
# Duplicate rows:
	# Issue where insertFromDNVGLRawIntoRaw will insert duplicates if given
	# Requirements for data returned when duplicate inserts attempted: all transactions logged somewhere? row numbers returned in output?
	# Requirements for detection of data duplication:
		If duplicates detected on key columns, can we see when other columns are different? Yes, ROW_COUNT after on duplicate key update = 0 when no change, = N when N rows changed.
		# Negative consequences of puttin unique key contraints on only IDENTIFYING columns (ie IMO, Time)? This would allow updating the non-key columns, otherwise deletion necessary. 
		# Replace withoutDuplicates syntax with unique constraints
			# Drop rawdata, write constraint into create script
			# Drop dnvglraw, write constraint into create script
			# Drop performanceData, write constraint into create script
			# Drop DNVGLperformanceData, write constraint into create script
			# Replace insertWithoutDuplicates with new cMySQL
			# Rewrite insertFromDNVGLRawIntoRaw to call ON DUPLICATE KEY UPDATE
			# Rewrite insertIntoPerformanceData to call ON DUPLICATE KEY UPDATE
	Performance comparison with alternatives
Access database:
	# from external machince
	via internet

Finalise processing of data from various sources:
	Write remainder of MATLAB code: insertIntoSFOCCoefficients, insertIntoOthers
	Write single-call procedure for ISO on raw, insert into performance
	
Implement Annex E to go from annemometre-height wind to reference-height wind
# Rename "Database" to "Vessel Performance Database"

Convert insertIntoTable into cMySQL method
removeNullRows: set filter for rows where any primary or secondary parameter is NULL
Write ON DUPLICATE KEY UPDATE calls into tables:
	BunkerDeliveryNote
	DryDockDates
	SFOCCoefficints
	SpeedPower
	SpeedPowerCoefficients
	VesselCoating
	Vessels
	windcoefficientdirection: Unique(imo, start direction) and Unique(imo, end direction)
	
insertBunkerDeliveryNoteDNVGL: convert from function to method of cVesselDB, use insertDuplicate
# rename table PerformanceDataDNVGL to DNVGLPerformanceData
create high-level table for "meta-data" of performance data
# remove table "ships", replace relevant data into "vessels"
# Write "use hull_performance" at start of all files
Procedure to call ISO19030 with input filters, add data to performance.
Allow MATLAB table output from SQL queries
Write code for (re-)building DB from downloaded files
Write timestep into metadata table for each vessel, parameter

Apply appropriate iteration to methods:
  regressions
  movingAverages

# cVA.filterOnUniqueIndex: allow only unique values, remove corresponding 
# non-unique values in other variables
Store variable names defined for files
isFileDNVGLRaw: detect if file contains data from DNVGL "Manage Data"
isFileDNVGLProcessed: detect if file contains data from EI widgets
fileTypes: function to determine type of each element of cellstr FILENAME
loadDNVGLRaw: return IMO of contained vessels as additional output
cMySQL.executeIfOneOutput: modify to (include) zero output, if class 
	remains handle.
cVessel.readFromVessels: populate data from table "vessels"
cVessel.readFromTable: match object properties to table columns
cV.constructor: error if one name and multiple imo input
# cV.iterReset: if finished, reset Iter to zero
cV.cV: include input to specify loading function
# write cV.iterReset after all while ~obj.iterFinished so that cV can be 
# 	value class again.